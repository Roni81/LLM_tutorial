{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28376882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /opt/anaconda3/envs/udemy_llm/lib/python3.13/site-packages (0.33.4)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/udemy_llm/lib/python3.13/site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/udemy_llm/lib/python3.13/site-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/envs/udemy_llm/lib/python3.13/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/udemy_llm/lib/python3.13/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/udemy_llm/lib/python3.13/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/envs/udemy_llm/lib/python3.13/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/udemy_llm/lib/python3.13/site-packages (from huggingface_hub) (4.13.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/envs/udemy_llm/lib/python3.13/site-packages (from huggingface_hub) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/udemy_llm/lib/python3.13/site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/udemy_llm/lib/python3.13/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/udemy_llm/lib/python3.13/site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/udemy_llm/lib/python3.13/site-packages (from requests->huggingface_hub) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0cb859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "\n",
    "from huggingface_hub import login\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from diffusers import DiffusionPipeline\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffaa716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd3fd462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f71ca476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea80a46df9743b38af661a049127e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7667f910",
   "metadata": {},
   "source": [
    "### Llama Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36448674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac70864189e440d98408048291eee87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b07621b3bb34f1d970d15afdaf0bc6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053951271bdd41b3994bb37a3f558670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3.1-8B\",\n",
    "    token = hf_token,\n",
    "    trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1f104aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I am excited to show Tokenizers in action to my LLM engineers'\n",
    "tokens = tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcb24d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e9952c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128000,\n",
       " 40,\n",
       " 1097,\n",
       " 12304,\n",
       " 311,\n",
       " 1501,\n",
       " 9857,\n",
       " 12509,\n",
       " 304,\n",
       " 1957,\n",
       " 311,\n",
       " 856,\n",
       " 445,\n",
       " 11237,\n",
       " 25175]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens\n",
    "# encode of the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28c792a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>I am excited to show Tokenizers in action to my LLM engineers'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens)\n",
    "# decode of the tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9873a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|>',\n",
       " 'I',\n",
       " ' am',\n",
       " ' excited',\n",
       " ' to',\n",
       " ' show',\n",
       " ' Token',\n",
       " 'izers',\n",
       " ' in',\n",
       " ' action',\n",
       " ' to',\n",
       " ' my',\n",
       " ' L',\n",
       " 'LM',\n",
       " ' engineers']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(tokens)\n",
    "# batch decode of the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a64a754f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<|begin_of_text|>': 128000,\n",
       " '<|end_of_text|>': 128001,\n",
       " '<|reserved_special_token_0|>': 128002,\n",
       " '<|reserved_special_token_1|>': 128003,\n",
       " '<|finetune_right_pad_id|>': 128004,\n",
       " '<|reserved_special_token_2|>': 128005,\n",
       " '<|start_header_id|>': 128006,\n",
       " '<|end_header_id|>': 128007,\n",
       " '<|eom_id|>': 128008,\n",
       " '<|eot_id|>': 128009,\n",
       " '<|python_tag|>': 128010,\n",
       " '<|reserved_special_token_3|>': 128011,\n",
       " '<|reserved_special_token_4|>': 128012,\n",
       " '<|reserved_special_token_5|>': 128013,\n",
       " '<|reserved_special_token_6|>': 128014,\n",
       " '<|reserved_special_token_7|>': 128015,\n",
       " '<|reserved_special_token_8|>': 128016,\n",
       " '<|reserved_special_token_9|>': 128017,\n",
       " '<|reserved_special_token_10|>': 128018,\n",
       " '<|reserved_special_token_11|>': 128019,\n",
       " '<|reserved_special_token_12|>': 128020,\n",
       " '<|reserved_special_token_13|>': 128021,\n",
       " '<|reserved_special_token_14|>': 128022,\n",
       " '<|reserved_special_token_15|>': 128023,\n",
       " '<|reserved_special_token_16|>': 128024,\n",
       " '<|reserved_special_token_17|>': 128025,\n",
       " '<|reserved_special_token_18|>': 128026,\n",
       " '<|reserved_special_token_19|>': 128027,\n",
       " '<|reserved_special_token_20|>': 128028,\n",
       " '<|reserved_special_token_21|>': 128029,\n",
       " '<|reserved_special_token_22|>': 128030,\n",
       " '<|reserved_special_token_23|>': 128031,\n",
       " '<|reserved_special_token_24|>': 128032,\n",
       " '<|reserved_special_token_25|>': 128033,\n",
       " '<|reserved_special_token_26|>': 128034,\n",
       " '<|reserved_special_token_27|>': 128035,\n",
       " '<|reserved_special_token_28|>': 128036,\n",
       " '<|reserved_special_token_29|>': 128037,\n",
       " '<|reserved_special_token_30|>': 128038,\n",
       " '<|reserved_special_token_31|>': 128039,\n",
       " '<|reserved_special_token_32|>': 128040,\n",
       " '<|reserved_special_token_33|>': 128041,\n",
       " '<|reserved_special_token_34|>': 128042,\n",
       " '<|reserved_special_token_35|>': 128043,\n",
       " '<|reserved_special_token_36|>': 128044,\n",
       " '<|reserved_special_token_37|>': 128045,\n",
       " '<|reserved_special_token_38|>': 128046,\n",
       " '<|reserved_special_token_39|>': 128047,\n",
       " '<|reserved_special_token_40|>': 128048,\n",
       " '<|reserved_special_token_41|>': 128049,\n",
       " '<|reserved_special_token_42|>': 128050,\n",
       " '<|reserved_special_token_43|>': 128051,\n",
       " '<|reserved_special_token_44|>': 128052,\n",
       " '<|reserved_special_token_45|>': 128053,\n",
       " '<|reserved_special_token_46|>': 128054,\n",
       " '<|reserved_special_token_47|>': 128055,\n",
       " '<|reserved_special_token_48|>': 128056,\n",
       " '<|reserved_special_token_49|>': 128057,\n",
       " '<|reserved_special_token_50|>': 128058,\n",
       " '<|reserved_special_token_51|>': 128059,\n",
       " '<|reserved_special_token_52|>': 128060,\n",
       " '<|reserved_special_token_53|>': 128061,\n",
       " '<|reserved_special_token_54|>': 128062,\n",
       " '<|reserved_special_token_55|>': 128063,\n",
       " '<|reserved_special_token_56|>': 128064,\n",
       " '<|reserved_special_token_57|>': 128065,\n",
       " '<|reserved_special_token_58|>': 128066,\n",
       " '<|reserved_special_token_59|>': 128067,\n",
       " '<|reserved_special_token_60|>': 128068,\n",
       " '<|reserved_special_token_61|>': 128069,\n",
       " '<|reserved_special_token_62|>': 128070,\n",
       " '<|reserved_special_token_63|>': 128071,\n",
       " '<|reserved_special_token_64|>': 128072,\n",
       " '<|reserved_special_token_65|>': 128073,\n",
       " '<|reserved_special_token_66|>': 128074,\n",
       " '<|reserved_special_token_67|>': 128075,\n",
       " '<|reserved_special_token_68|>': 128076,\n",
       " '<|reserved_special_token_69|>': 128077,\n",
       " '<|reserved_special_token_70|>': 128078,\n",
       " '<|reserved_special_token_71|>': 128079,\n",
       " '<|reserved_special_token_72|>': 128080,\n",
       " '<|reserved_special_token_73|>': 128081,\n",
       " '<|reserved_special_token_74|>': 128082,\n",
       " '<|reserved_special_token_75|>': 128083,\n",
       " '<|reserved_special_token_76|>': 128084,\n",
       " '<|reserved_special_token_77|>': 128085,\n",
       " '<|reserved_special_token_78|>': 128086,\n",
       " '<|reserved_special_token_79|>': 128087,\n",
       " '<|reserved_special_token_80|>': 128088,\n",
       " '<|reserved_special_token_81|>': 128089,\n",
       " '<|reserved_special_token_82|>': 128090,\n",
       " '<|reserved_special_token_83|>': 128091,\n",
       " '<|reserved_special_token_84|>': 128092,\n",
       " '<|reserved_special_token_85|>': 128093,\n",
       " '<|reserved_special_token_86|>': 128094,\n",
       " '<|reserved_special_token_87|>': 128095,\n",
       " '<|reserved_special_token_88|>': 128096,\n",
       " '<|reserved_special_token_89|>': 128097,\n",
       " '<|reserved_special_token_90|>': 128098,\n",
       " '<|reserved_special_token_91|>': 128099,\n",
       " '<|reserved_special_token_92|>': 128100,\n",
       " '<|reserved_special_token_93|>': 128101,\n",
       " '<|reserved_special_token_94|>': 128102,\n",
       " '<|reserved_special_token_95|>': 128103,\n",
       " '<|reserved_special_token_96|>': 128104,\n",
       " '<|reserved_special_token_97|>': 128105,\n",
       " '<|reserved_special_token_98|>': 128106,\n",
       " '<|reserved_special_token_99|>': 128107,\n",
       " '<|reserved_special_token_100|>': 128108,\n",
       " '<|reserved_special_token_101|>': 128109,\n",
       " '<|reserved_special_token_102|>': 128110,\n",
       " '<|reserved_special_token_103|>': 128111,\n",
       " '<|reserved_special_token_104|>': 128112,\n",
       " '<|reserved_special_token_105|>': 128113,\n",
       " '<|reserved_special_token_106|>': 128114,\n",
       " '<|reserved_special_token_107|>': 128115,\n",
       " '<|reserved_special_token_108|>': 128116,\n",
       " '<|reserved_special_token_109|>': 128117,\n",
       " '<|reserved_special_token_110|>': 128118,\n",
       " '<|reserved_special_token_111|>': 128119,\n",
       " '<|reserved_special_token_112|>': 128120,\n",
       " '<|reserved_special_token_113|>': 128121,\n",
       " '<|reserved_special_token_114|>': 128122,\n",
       " '<|reserved_special_token_115|>': 128123,\n",
       " '<|reserved_special_token_116|>': 128124,\n",
       " '<|reserved_special_token_117|>': 128125,\n",
       " '<|reserved_special_token_118|>': 128126,\n",
       " '<|reserved_special_token_119|>': 128127,\n",
       " '<|reserved_special_token_120|>': 128128,\n",
       " '<|reserved_special_token_121|>': 128129,\n",
       " '<|reserved_special_token_122|>': 128130,\n",
       " '<|reserved_special_token_123|>': 128131,\n",
       " '<|reserved_special_token_124|>': 128132,\n",
       " '<|reserved_special_token_125|>': 128133,\n",
       " '<|reserved_special_token_126|>': 128134,\n",
       " '<|reserved_special_token_127|>': 128135,\n",
       " '<|reserved_special_token_128|>': 128136,\n",
       " '<|reserved_special_token_129|>': 128137,\n",
       " '<|reserved_special_token_130|>': 128138,\n",
       " '<|reserved_special_token_131|>': 128139,\n",
       " '<|reserved_special_token_132|>': 128140,\n",
       " '<|reserved_special_token_133|>': 128141,\n",
       " '<|reserved_special_token_134|>': 128142,\n",
       " '<|reserved_special_token_135|>': 128143,\n",
       " '<|reserved_special_token_136|>': 128144,\n",
       " '<|reserved_special_token_137|>': 128145,\n",
       " '<|reserved_special_token_138|>': 128146,\n",
       " '<|reserved_special_token_139|>': 128147,\n",
       " '<|reserved_special_token_140|>': 128148,\n",
       " '<|reserved_special_token_141|>': 128149,\n",
       " '<|reserved_special_token_142|>': 128150,\n",
       " '<|reserved_special_token_143|>': 128151,\n",
       " '<|reserved_special_token_144|>': 128152,\n",
       " '<|reserved_special_token_145|>': 128153,\n",
       " '<|reserved_special_token_146|>': 128154,\n",
       " '<|reserved_special_token_147|>': 128155,\n",
       " '<|reserved_special_token_148|>': 128156,\n",
       " '<|reserved_special_token_149|>': 128157,\n",
       " '<|reserved_special_token_150|>': 128158,\n",
       " '<|reserved_special_token_151|>': 128159,\n",
       " '<|reserved_special_token_152|>': 128160,\n",
       " '<|reserved_special_token_153|>': 128161,\n",
       " '<|reserved_special_token_154|>': 128162,\n",
       " '<|reserved_special_token_155|>': 128163,\n",
       " '<|reserved_special_token_156|>': 128164,\n",
       " '<|reserved_special_token_157|>': 128165,\n",
       " '<|reserved_special_token_158|>': 128166,\n",
       " '<|reserved_special_token_159|>': 128167,\n",
       " '<|reserved_special_token_160|>': 128168,\n",
       " '<|reserved_special_token_161|>': 128169,\n",
       " '<|reserved_special_token_162|>': 128170,\n",
       " '<|reserved_special_token_163|>': 128171,\n",
       " '<|reserved_special_token_164|>': 128172,\n",
       " '<|reserved_special_token_165|>': 128173,\n",
       " '<|reserved_special_token_166|>': 128174,\n",
       " '<|reserved_special_token_167|>': 128175,\n",
       " '<|reserved_special_token_168|>': 128176,\n",
       " '<|reserved_special_token_169|>': 128177,\n",
       " '<|reserved_special_token_170|>': 128178,\n",
       " '<|reserved_special_token_171|>': 128179,\n",
       " '<|reserved_special_token_172|>': 128180,\n",
       " '<|reserved_special_token_173|>': 128181,\n",
       " '<|reserved_special_token_174|>': 128182,\n",
       " '<|reserved_special_token_175|>': 128183,\n",
       " '<|reserved_special_token_176|>': 128184,\n",
       " '<|reserved_special_token_177|>': 128185,\n",
       " '<|reserved_special_token_178|>': 128186,\n",
       " '<|reserved_special_token_179|>': 128187,\n",
       " '<|reserved_special_token_180|>': 128188,\n",
       " '<|reserved_special_token_181|>': 128189,\n",
       " '<|reserved_special_token_182|>': 128190,\n",
       " '<|reserved_special_token_183|>': 128191,\n",
       " '<|reserved_special_token_184|>': 128192,\n",
       " '<|reserved_special_token_185|>': 128193,\n",
       " '<|reserved_special_token_186|>': 128194,\n",
       " '<|reserved_special_token_187|>': 128195,\n",
       " '<|reserved_special_token_188|>': 128196,\n",
       " '<|reserved_special_token_189|>': 128197,\n",
       " '<|reserved_special_token_190|>': 128198,\n",
       " '<|reserved_special_token_191|>': 128199,\n",
       " '<|reserved_special_token_192|>': 128200,\n",
       " '<|reserved_special_token_193|>': 128201,\n",
       " '<|reserved_special_token_194|>': 128202,\n",
       " '<|reserved_special_token_195|>': 128203,\n",
       " '<|reserved_special_token_196|>': 128204,\n",
       " '<|reserved_special_token_197|>': 128205,\n",
       " '<|reserved_special_token_198|>': 128206,\n",
       " '<|reserved_special_token_199|>': 128207,\n",
       " '<|reserved_special_token_200|>': 128208,\n",
       " '<|reserved_special_token_201|>': 128209,\n",
       " '<|reserved_special_token_202|>': 128210,\n",
       " '<|reserved_special_token_203|>': 128211,\n",
       " '<|reserved_special_token_204|>': 128212,\n",
       " '<|reserved_special_token_205|>': 128213,\n",
       " '<|reserved_special_token_206|>': 128214,\n",
       " '<|reserved_special_token_207|>': 128215,\n",
       " '<|reserved_special_token_208|>': 128216,\n",
       " '<|reserved_special_token_209|>': 128217,\n",
       " '<|reserved_special_token_210|>': 128218,\n",
       " '<|reserved_special_token_211|>': 128219,\n",
       " '<|reserved_special_token_212|>': 128220,\n",
       " '<|reserved_special_token_213|>': 128221,\n",
       " '<|reserved_special_token_214|>': 128222,\n",
       " '<|reserved_special_token_215|>': 128223,\n",
       " '<|reserved_special_token_216|>': 128224,\n",
       " '<|reserved_special_token_217|>': 128225,\n",
       " '<|reserved_special_token_218|>': 128226,\n",
       " '<|reserved_special_token_219|>': 128227,\n",
       " '<|reserved_special_token_220|>': 128228,\n",
       " '<|reserved_special_token_221|>': 128229,\n",
       " '<|reserved_special_token_222|>': 128230,\n",
       " '<|reserved_special_token_223|>': 128231,\n",
       " '<|reserved_special_token_224|>': 128232,\n",
       " '<|reserved_special_token_225|>': 128233,\n",
       " '<|reserved_special_token_226|>': 128234,\n",
       " '<|reserved_special_token_227|>': 128235,\n",
       " '<|reserved_special_token_228|>': 128236,\n",
       " '<|reserved_special_token_229|>': 128237,\n",
       " '<|reserved_special_token_230|>': 128238,\n",
       " '<|reserved_special_token_231|>': 128239,\n",
       " '<|reserved_special_token_232|>': 128240,\n",
       " '<|reserved_special_token_233|>': 128241,\n",
       " '<|reserved_special_token_234|>': 128242,\n",
       " '<|reserved_special_token_235|>': 128243,\n",
       " '<|reserved_special_token_236|>': 128244,\n",
       " '<|reserved_special_token_237|>': 128245,\n",
       " '<|reserved_special_token_238|>': 128246,\n",
       " '<|reserved_special_token_239|>': 128247,\n",
       " '<|reserved_special_token_240|>': 128248,\n",
       " '<|reserved_special_token_241|>': 128249,\n",
       " '<|reserved_special_token_242|>': 128250,\n",
       " '<|reserved_special_token_243|>': 128251,\n",
       " '<|reserved_special_token_244|>': 128252,\n",
       " '<|reserved_special_token_245|>': 128253,\n",
       " '<|reserved_special_token_246|>': 128254,\n",
       " '<|reserved_special_token_247|>': 128255}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizer.vocab\n",
    "tokenizer.get_added_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8c682f",
   "metadata": {},
   "source": [
    "### Instruct Variants of Models\n",
    "\n",
    "many models have a variant that has veen trained for use in Chats\n",
    "These are typically lavelled with the word \"instruct\" at the end.\n",
    "They have been trained to expect prompts with a particular format that includes system, user and assistant prompts.\n",
    "There is a utility method apply_chat_template that will convert from the messages list format we are familiar with into the right input prompt for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d79fdec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "135b142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3_chat_template = (\n",
    "    \"{% set loop_messages = messages %}\"\n",
    "    \"{% for message in loop_messages %}\"\n",
    "        \"{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n' + message['content'] | trim + '<|eot_id|>' %}\"\n",
    "        \"{% if loop.index0 == 0 %}\"\n",
    "            \"{% set content = bos_token + content %}\"\n",
    "        \"{% endif %}\"\n",
    "        \"{{ content }}\"\n",
    "    \"{% endfor %}\"\n",
    "    \"{% if add_generation_prompt %}\"\n",
    "        \"{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\"\n",
    "    \"{% endif %}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e92f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template = llama3_chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "926d3652",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\":\"system\", 'content': \"you are a helpful assistant\"},\n",
    "    {\"role\":\"user\", 'content': \"Tell me light-hearted joke for a room of data scientists\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a2b5c6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "you are a helpful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Tell me light-hearted joke for a room of data scientists<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors='pt')\n",
    "print(tokenizer.decode(prompt[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4416ac74",
   "metadata": {},
   "source": [
    "### Trying new models\n",
    "\n",
    "We will now work with 3 models\n",
    "Phi3 from MicroSoft Qwen2 from Alibaba Cloud Starcoder2 from BigCode(ServiceNow + HuggingFace + Nvidia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f04bb333",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHI3_MODEL_NAME = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "QWEN2_MODEL_NAME = \"Qwen/Qwen2-72B-Instruct\"\n",
    "STARCODER2_MODEL_NAME = 'bigcode/starcoder2-3b'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "033d344e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf25fb13b8a416ea3acc07c8b969fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd895c9e654e4f2294297717bc23311e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02de7e4e100240c7854282de2a783fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef67b3aa77264e7da60578b4d40ca153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3356d01893547309cebb292bea77517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/958 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phi3_tokenizer = AutoTokenizer.from_pretrained(PHI3_MODEL_NAME)\n",
    "qwen2_tokenizer = AutoTokenizer.from_pretrained(QWEN2_MODEL_NAME)\n",
    "starcoder2_tokenizer = AutoTokenizer.from_pretrained(STARCODER2_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "81b98fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi3_chat_template = (\n",
    "    \"{{ bos_token }}\"\n",
    "    \"{% for message in messages %}\"\n",
    "        \"{{ '<|' + message['role'] + '|>' + '\\n' + message['content'] + '<|end|>' + '\\n' }}\"\n",
    "    \"{% endfor %}\"\n",
    "    \"{% if add_generation_prompt %}\"\n",
    "        \"{{ '<|assistant|>\\n' }}\"\n",
    "    \"{% endif %}\"\n",
    ")\n",
    "qwen2_chat_template = (\n",
    "    \"{% for message in messages %}\"\n",
    "        \"{{ '<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n' }}\"\n",
    "    \"{% endfor %}\"\n",
    "    \"{% if add_generation_prompt %}\"\n",
    "        \"{{ '<|im_start|>assistant\\n' }}\"\n",
    "    \"{% endif %}\"\n",
    ")\n",
    "starcoder2_chat_template = (\n",
    "    \"{% for message in messages %}\"\n",
    "        \"{{ '<|' + message['role'] + '|>\\n' + message['content'] + '<|end|>\\n' }}\"\n",
    "    \"{% endfor %}\"\n",
    "    \"{% if add_generation_prompt %}\"\n",
    "        \"{{ '<|assistant|>' }}\"\n",
    "    \"{% endif %}\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "75e9319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\":\"system\", 'content': \"you are a helpful assistant\"},\n",
    "    {\"role\":\"user\", 'content': \"Tell me light-hearted joke for a room of data scientists\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9cc85290",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi3_tokenizer.chat_template = phi3_chat_template\n",
    "qwen2_tokenizer.chat_template = qwen2_chat_template\n",
    "starcoder2_tokenizer = starcoder2_chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c13e2cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I am excited to show Tokenizers in action to my LLM engineers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "615e4e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128000, 128006, 9125, 128007, 271, 9514, 527, 264, 11190, 18328, 128009, 128006, 882, 128007, 271, 41551, 757, 3177, 70395, 22380, 369, 264, 3130, 315, 828, 14248, 128009, 128006, 78191, 128007, 271]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[1, 32006, 366, 526, 263, 8444, 20255, 32007, 32010, 24948, 592, 3578, 29899, 23057, 287, 2958, 446, 363, 263, 5716, 310, 848, 9638, 2879, 32007, 32001]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[151644, 8948, 198, 9330, 525, 264, 10950, 17847, 151645, 198, 151644, 872, 198, 40451, 752, 3100, 69295, 21646, 369, 264, 3054, 315, 821, 13923, 151645, 198, 151644, 77091, 198]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'apply_chat_template'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(qwen2_tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(messages,\n\u001b[1;32m     12\u001b[0m                                     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m                                     add_generation_prompt\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m                                    ))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(starcoder2_tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(messages,\n\u001b[1;32m     17\u001b[0m                                     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m                                     add_generation_prompt\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,)\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'apply_chat_template'"
     ]
    }
   ],
   "source": [
    "print(tokenizer.apply_chat_template(messages,\n",
    "                                    tokenizer = False,\n",
    "                                    add_generation_prompt= True,\n",
    "                                   ))\n",
    "print('-'* 100)\n",
    "print(phi3_tokenizer.apply_chat_template(messages,\n",
    "                                    tokenizer = False,\n",
    "                                    add_generation_prompt= True,\n",
    "                                   ))\n",
    "print('-'* 100)\n",
    "print(qwen2_tokenizer.apply_chat_template(messages,\n",
    "                                    tokenizer = False,\n",
    "                                    add_generation_prompt= True,\n",
    "                                   ))\n",
    "print('-'* 100)\n",
    "print(starcoder2_tokenizer.apply_chat_template(messages,\n",
    "                                    tokenizer = False,\n",
    "                                    add_generation_prompt= True,)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "70cd046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen2_tokenizer = AutoTokenizer.from_pretrained(QWEN2_MODEL_NAME)\n",
    "\n",
    "text = 'I am excited to show Tokenizers in action to my LLM engineers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aee6344d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128000, 40, 1097, 12304, 311, 1501, 9857, 12509, 304, 1957, 311, 856, 445, 11237, 25175]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[306, 626, 24173, 304, 1510, 25159, 19427, 297, 3158, 304, 590, 365, 26369, 6012, 414]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[40, 1079, 12035, 311, 1473, 9660, 12230, 304, 1917, 311, 847, 444, 10994, 24198]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(text))\n",
    "print('-'* 100)\n",
    "print(phi3_tokenizer.encode(text))\n",
    "print('-'*100)\n",
    "print(qwen2_tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cec4868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 32006, 366, 526, 263, 8444, 20255, 32007, 32010, 24948, 592, 3578, 29899, 23057, 287, 2958, 446, 363, 263, 5716, 310, 848, 9638, 2879, 32007, 32001]\n"
     ]
    }
   ],
   "source": [
    "print(phi3_tokenizer.apply_chat_template(messages,\n",
    "                                    tokenizer = False,\n",
    "                                    add_generation_prompt= True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1fecd1e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'apply_chat_template'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m phi3_prompt \u001b[38;5;241m=\u001b[39m phi3_tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m      2\u001b[0m     messages,\n\u001b[1;32m      3\u001b[0m     tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m qwen2_prompt \u001b[38;5;241m=\u001b[39m qwen2_tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m      7\u001b[0m     messages,\n\u001b[1;32m      8\u001b[0m     tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m     add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m starcoder2_prompt \u001b[38;5;241m=\u001b[39m starcoder2_tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m     12\u001b[0m     messages,\n\u001b[1;32m     13\u001b[0m     tokenize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m     add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'apply_chat_template'"
     ]
    }
   ],
   "source": [
    "phi3_prompt = phi3_tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors='pt')\n",
    "qwen2_prompt = qwen2_tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors='pt')\n",
    "starcoder2_prompt = starcoder2_tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "55b710e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" traditions <angon Gl WE getStringDESC-carustABLE-def.ToolStripMenuIteming File(\"owon ful           loglettersection getString crossorigin\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<s><|system|> you are a helpful assistant<|end|><|user|> Tell me light-hearted joke for a room of data scientists<|end|><|assistant|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(prompt[0]))\n",
    "print('-'* 100)\n",
    "print(phi3_tokenizer.decode(phi3_prompt[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "31e5b907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "you are a helpful assistant<|im_end|>\n",
      "<|im_start|>user\n",
      "Tell me light-hearted joke for a room of data scientists<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(qwen2_tokenizer.decode(qwen2_prompt[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0b4e19c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "starcoder2_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    STARCODER2_MODEL_NAME,\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "67b79983",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "def hello_world():\n",
    "print(\"Hello, world!\",person)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1738c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = starcoder2_tokenizer.encode(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "48ff15b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[222,\n",
       " 610,\n",
       " 17966,\n",
       " 100,\n",
       " 5879,\n",
       " 2284,\n",
       " 222,\n",
       " 1243,\n",
       " 459,\n",
       " 8302,\n",
       " 49,\n",
       " 5810,\n",
       " 13700,\n",
       " 6427,\n",
       " 46,\n",
       " 222]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c3989412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222: \n",
      "\n",
      "610: def\n",
      "17966:  hello\n",
      "100: _\n",
      "5879: world\n",
      "2284: ():\n",
      "222: \n",
      "\n",
      "1243: print\n",
      "459: (\"\n",
      "8302: Hello\n",
      "49: ,\n",
      "5810:  world\n",
      "13700: !\",\n",
      "6427: person\n",
      "46: )\n",
      "222: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    print(f\"{token}: {starcoder2_tokenizer.decode(token)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd8d6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udemy_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
