{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c24f22a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ bitsandbytesÍ∞Ä ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏÑ§Ïπò Î∞è import ÎêòÏóàÏäµÎãàÎã§.\n",
      "‚úÖ 4ÎπÑÌä∏ ÏñëÏûêÌôî ÏÑ§Ï†ïÏù¥ Í∞ÄÎä•ÌïòÎ©∞, MPSÎ•º ÏÇ¨Ïö©Ìï† Ï§ÄÎπÑÍ∞Ä ÎêòÏóàÏäµÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "try:\n",
    "    from transformers import BitsAndBytesConfig\n",
    "    print(\"‚úÖ bitsandbytesÍ∞Ä ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏÑ§Ïπò Î∞è import ÎêòÏóàÏäµÎãàÎã§.\")\n",
    "    \n",
    "    # MPS(M3 GPU)ÏóêÏÑú 4ÎπÑÌä∏ ÏñëÏûêÌôîÍ∞Ä Í∞ÄÎä•ÌïúÏßÄ ÏµúÏ¢Ö ÌôïÏù∏\n",
    "    if torch.backends.mps.is_available():\n",
    "        bnb_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "        print(\"‚úÖ 4ÎπÑÌä∏ ÏñëÏûêÌôî ÏÑ§Ï†ïÏù¥ Í∞ÄÎä•ÌïòÎ©∞, MPSÎ•º ÏÇ¨Ïö©Ìï† Ï§ÄÎπÑÍ∞Ä ÎêòÏóàÏäµÎãàÎã§.\")\n",
    "    else:\n",
    "        print(\"üü° bitsandbytesÎäî ÏÑ§ÏπòÎêòÏóàÏúºÎÇò, MPSÎ•º ÏÇ¨Ïö©Ìï† Ïàò ÏóÜÏäµÎãàÎã§.\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"‚ùå ImportÏóê Ïã§Ìå®ÌñàÏäµÎãàÎã§. ÎπåÎìú Í≥ºÏ†ïÏóêÏÑú ÏóêÎü¨Í∞Ä Î∞úÏÉùÌñàÏùÑ Ïàò ÏûàÏäµÎãàÎã§.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Îã§Î•∏ ÏóêÎü¨ Î∞úÏÉù: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86a8ed90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from torchvision) (2.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (0.47.0.dev0)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (4.53.3)\n",
      "Requirement already satisfied: accelerate in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (1.9.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (1.1.1)\n",
      "Requirement already satisfied: jupyter in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (1.1.1)\n",
      "Requirement already satisfied: torch<3,>=2.2 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from bitsandbytes) (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from bitsandbytes) (2.3.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (2025.7.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: notebook in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter) (7.4.4)\n",
      "Requirement already satisfied: jupyter-console in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter) (8.1.7)\n",
      "Requirement already satisfied: jupyterlab in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter) (4.4.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: appnope in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipykernel->jupyter) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipykernel->jupyter) (1.8.11)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipykernel->jupyter) (9.4.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipykernel->jupyter) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipykernel->jupyter) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipykernel->jupyter) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->jupyter) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->jupyter) (1.17.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipywidgets->jupyter) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from ipywidgets->jupyter) (3.0.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyterlab->jupyter) (2.0.5)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyterlab->jupyter) (0.28.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyterlab->jupyter) (2.2.6)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyterlab->jupyter) (2.16.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyterlab->jupyter) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyterlab->jupyter) (78.1.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (4.9.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.22.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.25.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (21.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.26.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.3.0)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.1.0)\n",
      "Requirement already satisfied: uri-template in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from nbconvert->jupyter) (4.13.4)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from nbconvert->jupyter) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from nbconvert->jupyter) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.21.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: lark>=1.2.2 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.2.2)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.7)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.9.0.20250708)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/anaconda3/envs/llm_env/lib/python3.11/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "# PyTorchÎ•º Î®ºÏ†Ä ÏÑ§ÏπòÌï©ÎãàÎã§ (MPS ÏßÄÏõêÏùÑ ÏúÑÌï¥ ÌïÑÏàò).\n",
    "!pip install torch torchvision torchaudio\n",
    "\n",
    "# Í∑∏ Îã§Ïùå, ÎÇòÎ®∏ÏßÄ ÎùºÏù¥Î∏åÎü¨Î¶¨Îì§ÏùÑ ÏÑ§ÏπòÌï©ÎãàÎã§.\n",
    "!pip install bitsandbytes transformers accelerate python-dotenv jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "258e7253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TextStreamer\n",
    "from huggingface_hub import login\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49d8c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54aed782",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "010804bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Hugging Face Î°úÍ∑∏Ïù∏Ïù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "if hf_token:\n",
    "    login(token=hf_token)\n",
    "    print(\"‚úÖ Hugging Face Î°úÍ∑∏Ïù∏Ïù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§.\")\n",
    "else:\n",
    "    print(\"‚ùóÔ∏è HUGGINGFACE_TOKENÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. .env ÌååÏùºÏùÑ ÌôïÏù∏ÌïòÏÑ∏Ïöî.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "655c59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "PHI3 = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "GEMMA2 = \"google/gemma-2-2b-it\"\n",
    "QWEN2 = \"Qwen/Qwen2-7B-Instruct\" # exercise for you\n",
    "MIXTRAL = \"mistralai/Mixtral-8x7B-Instruct-v0.1\" # If this doesn't fit it your GPU memory, try others from the hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3d984c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tell me light-hearted joke for a room of data scientists\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e31ff4",
   "metadata": {},
   "source": [
    "#### Accessing Llama3.1 from meta\n",
    "\n",
    "In order to use the fantastic Llama 3.1, Meta does require you to sign their terms of service.\n",
    "\n",
    "Visit their model instructions page in Hugging Face:\n",
    "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B\n",
    "\n",
    "At the top of the page are instructions on how to agree to their terms. If possible, you should use the same email as your huggingface account.\n",
    "\n",
    "In my experience approval comes in a couple of minutes. Once you've been approved for any 3.1 model, it applies to the whole family of models.\n",
    "\n",
    "If you have any problems accessing Llama, please see this colab, including some suggestions if you don't get approved by Meta for any reason.\n",
    "\n",
    "https://colab.research.google.com/drive/1deJO03YZTXUwcq2vzxWbiBhrRuI29Vo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7dbd430",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e5637dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    LLAMA,\n",
    "    use_fast=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "input = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    llm_int8_enable_fp32_cpu_offload=True,\n",
    "    return_tensors = \"pt\"\n",
    ").to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e79e3549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 8-bit optimizer is not available on your device, only available on CUDA for now.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c265331d65e548f98519e48d4f6e1323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc24432f3b842c49cbd076ce0e24fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    LLAMA,\n",
    "    quantization_config=quant_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de26b0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ ÏñëÏûêÌôîÎêú Î™®Îç∏ÏùÑ Î°úÏª¨Ïóê Ï†ÄÏû•Ìï©ÎãàÎã§...\n",
      "‚úÖ Ï†ÄÏû• ÏôÑÎ£å!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ÏñëÏûêÌôîÎêú Î™®Îç∏ÏùÑ Î°úÏª¨Ïóê Ï†ÄÏû•\n",
    "print(\"üíæ ÏñëÏûêÌôîÎêú Î™®Îç∏ÏùÑ Î°úÏª¨Ïóê Ï†ÄÏû•Ìï©ÎãàÎã§...\")\n",
    "model.save_pretrained(\"./Llama-2-7b-chat-hf-4bit\")\n",
    "tokenizer.save_pretrained(\"./Llama-2-7b-chat-hf-4bit\")\n",
    "print(\"‚úÖ Ï†ÄÏû• ÏôÑÎ£å!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c0bd473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Ï†ÄÏû•Îêú 4ÎπÑÌä∏ Î™®Îç∏ÏùÑ Îπ†Î•¥Í≤å Î°úÎî©Ìï©ÎãàÎã§...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LlamaForCausalLM.__init__() got an unexpected keyword argument 'llm_int8_enable_fp32_cpu_offload'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 2. Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# device_map=\"auto\" ÏòµÏÖòÏùÄ Î™®Îç∏ÏùÑ MPS(GPU)Ïóê ÏûêÎèôÏúºÎ°ú Ìï†ÎãπÌï¥Ï§çÎãàÎã§.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müöÄ Ï†ÄÏû•Îêú 4ÎπÑÌä∏ Î™®Îç∏ÏùÑ Îπ†Î•¥Í≤å Î°úÎî©Ìï©ÎãàÎã§...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm_int8_enable_fp32_cpu_offload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 3. ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î∂àÎü¨Ïò§Í∏∞\u001b[39;00m\n\u001b[32m     12\u001b[39m tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llm_env/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:600\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    599\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    604\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    605\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    606\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llm_env/lib/python3.11/site-packages/transformers/modeling_utils.py:311\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    309\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    313\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llm_env/lib/python3.11/site-packages/transformers/modeling_utils.py:4766\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4758\u001b[39m     config = \u001b[38;5;28mcls\u001b[39m._autoset_attn_implementation(\n\u001b[32m   4759\u001b[39m         config,\n\u001b[32m   4760\u001b[39m         torch_dtype=torch_dtype,\n\u001b[32m   4761\u001b[39m         device_map=device_map,\n\u001b[32m   4762\u001b[39m     )\n\u001b[32m   4764\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(model_init_context):\n\u001b[32m   4765\u001b[39m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4766\u001b[39m     model = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4768\u001b[39m \u001b[38;5;66;03m# Make sure to tie the weights correctly\u001b[39;00m\n\u001b[32m   4769\u001b[39m model.tie_weights()\n",
      "\u001b[31mTypeError\u001b[39m: LlamaForCausalLM.__init__() got an unexpected keyword argument 'llm_int8_enable_fp32_cpu_offload'"
     ]
    }
   ],
   "source": [
    "local_model_path = \"/Users/sungminhong/Documents/Udemi/LLM_tutorial/3rd_week/Llama-2-7b-chat-hf-4bit\"\n",
    "\n",
    "# 2. Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\n",
    "# device_map=\"auto\" ÏòµÏÖòÏùÄ Î™®Îç∏ÏùÑ MPS(GPU)Ïóê ÏûêÎèôÏúºÎ°ú Ìï†ÎãπÌï¥Ï§çÎãàÎã§.\n",
    "print(\"üöÄ Ï†ÄÏû•Îêú 4ÎπÑÌä∏ Î™®Îç∏ÏùÑ Îπ†Î•¥Í≤å Î°úÎî©Ìï©ÎãàÎã§...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    local_model_path,\n",
    "    llm_int8_enable_fp32_cpu_offload=True\n",
    ")\n",
    "\n",
    "# 3. ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î∂àÎü¨Ïò§Í∏∞\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "\n",
    "print(\"‚úÖ Î°úÎî© ÏôÑÎ£å!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a939af4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LlamaForCausalLM.__init__() got an unexpected keyword argument 'llm_int8_enable_fp32_cpu_offload'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m local_model_path = \u001b[33m\"\u001b[39m\u001b[33m./Llama-2-7b-chat-hf-4bit\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm_int8_enable_fp32_cpu_offload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# ÏóÖÍ∑∏Î†àÏù¥Îìú ÌõÑÏóêÎäî Ïù¥ ÏòµÏÖòÏù¥ Ï†ïÏÉÅ ÏûëÎèôÌï©ÎãàÎã§.\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î∂àÎü¨Ïò§Í∏∞\u001b[39;00m\n\u001b[32m     14\u001b[39m tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llm_env/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:600\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    599\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    604\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    605\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    606\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llm_env/lib/python3.11/site-packages/transformers/modeling_utils.py:311\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    309\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    313\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llm_env/lib/python3.11/site-packages/transformers/modeling_utils.py:4766\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4758\u001b[39m     config = \u001b[38;5;28mcls\u001b[39m._autoset_attn_implementation(\n\u001b[32m   4759\u001b[39m         config,\n\u001b[32m   4760\u001b[39m         torch_dtype=torch_dtype,\n\u001b[32m   4761\u001b[39m         device_map=device_map,\n\u001b[32m   4762\u001b[39m     )\n\u001b[32m   4764\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(model_init_context):\n\u001b[32m   4765\u001b[39m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4766\u001b[39m     model = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4768\u001b[39m \u001b[38;5;66;03m# Make sure to tie the weights correctly\u001b[39;00m\n\u001b[32m   4769\u001b[39m model.tie_weights()\n",
      "\u001b[31mTypeError\u001b[39m: LlamaForCausalLM.__init__() got an unexpected keyword argument 'llm_int8_enable_fp32_cpu_offload'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Ï†ÄÏû•Îêú Î™®Îç∏ Í≤ΩÎ°ú\n",
    "local_model_path = \"./Llama-2-7b-chat-hf-4bit\"\n",
    "\n",
    "# Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    local_model_path,\n",
    "    device_map=\"auto\",\n",
    "    llm_int8_enable_fp32_cpu_offload=True # ÏóÖÍ∑∏Î†àÏù¥Îìú ÌõÑÏóêÎäî Ïù¥ ÏòµÏÖòÏù¥ Ï†ïÏÉÅ ÏûëÎèôÌï©ÎãàÎã§.\n",
    ")\n",
    "\n",
    "# ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î∂àÎü¨Ïò§Í∏∞\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "\n",
    "print(\"‚úÖ Î°úÎî© ÏôÑÎ£å!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fca4b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
